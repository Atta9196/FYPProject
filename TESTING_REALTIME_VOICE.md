# Testing Realtime Voice Conversation

## âœ… Implementation Checklist

### What's Implemented:
1. âœ… `input_audio_buffer.start` - Sent when audio capture begins
2. âœ… Audio chunks sent via data channel as binary PCM data
3. âœ… `input_audio_buffer.commit` - Sent when stopping (optional)
4. âœ… Silence timeout set to 4000ms (4 seconds)
5. âœ… Audio playback button for browser autoplay restrictions
6. âœ… Audio capture pipeline with AudioContext
7. âœ… PCM 16-bit audio format conversion

## ğŸš€ Testing Steps

### 1. Start the Server

```powershell
cd E:\IeltsCoach\IeltsWeb\server
npm install  # If dependencies not installed
npm start
```

**Expected Output:**
- Server should start on port 5000 (or configured port)
- Should see: `âœ… OpenAI API Key configured`
- Should see: `Server running on port...`

### 2. Start the Client

```powershell
cd E:\IeltsCoach\IeltsWeb\client
npm install  # If dependencies not installed
npm run dev
```

**Expected Output:**
- Vite dev server should start
- Usually runs on `http://localhost:5173` or similar

### 3. Open Browser and Test

1. **Open the app** in Chrome/Edge (HTTPS or localhost)
   - Navigate to the speaking practice page
   - Open Developer Tools (F12)

2. **Check Console Logs** - Look for these key messages:

   **On Connection:**
   ```
   âœ… Data channel opened for text messages
   âœ… Sent session update with turn detection settings
   âœ… Sent Part 1 start request
   âœ… Started sending audio to OpenAI via data channel
   âœ… Audio capture pipeline set up - ready to send audio chunks
   ```

   **When Speaking:**
   ```
   ğŸ¤ User started speaking
   ğŸ“ Partial user transcription: [your words]
   âœ… Complete user transcription: [your words]
   ```

   **When AI Responds:**
   ```
   ğŸ“ AI text delta: [AI response]
   âœ… AI response completed: [full response]
   â–¶ï¸ AI audio started playing
   ```

3. **Test Audio Flow:**

   **Step 1: Start Session**
   - Click "Start Voice Conversation"
   - Allow microphone permission if prompted
   - Should see: "âœ… Connected via Realtime API"

   **Step 2: Check Audio Sending**
   - Look for: `âœ… Started sending audio to OpenAI via data channel`
   - Speak into microphone
   - Check console for continuous audio chunk sending (no errors)

   **Step 3: Test Conversation**
   - AI should ask first question
   - Speak your answer (wait for AI to finish speaking)
   - AI should respond to what you said (not generic response)
   - Should wait 4 seconds of silence before responding

   **Step 4: Audio Playback**
   - If audio doesn't play automatically, click "ğŸ”Š Click to Start Audio" button
   - Should hear AI voice responses

## ğŸ” Debugging Checklist

### If Audio Not Sending:

1. **Check Microphone Permission:**
   - Browser address bar â†’ Click lock/info icon
   - Ensure microphone is "Allow"
   - Refresh page if needed

2. **Check Console Errors:**
   - Look for: `âŒ Error sending audio chunk`
   - Look for: `âš ï¸ Data channel not open`
   - Look for: `âŒ Error starting audio capture`

3. **Verify Variables:**
   ```javascript
   // In browser console, check:
   console.log('isCapturingAudio:', isCapturingAudio);
   console.log('dataChannel readyState:', dataChannel?.readyState);
   ```

4. **Check Audio Context:**
   - Look for: `âœ… Audio capture pipeline set up`
   - If missing, check for AudioContext errors

### If AI Not Responding:

1. **Check Backend Logs:**
   - Look for: `response.audio.delta` events
   - Should see continuous audio data from AI

2. **Check Silence Detection:**
   - Speak clearly and wait 4 seconds of silence
   - AI should respond after silence

3. **Check Turn Detection:**
   - Server config: `silence_duration_ms: 4000`
   - Should wait 4 seconds before responding

### If Multiple Questions Fired:

1. **Check Audio Sending:**
   - OpenAI sees silence â†’ thinks user finished â†’ asks next question
   - Verify audio chunks are being sent (check console)

2. **Check `input_audio_buffer.start`:**
   - Should see: `âœ… Started sending audio to OpenAI via data channel`
   - If missing, audio won't be sent

## ğŸ“Š Expected Console Flow

### Successful Connection:
```
ğŸ™ï¸ Creating Realtime API session...
âœ… Realtime session created: [session-id]
âœ… Data channel created
âœ… Data channel opened for text messages
âœ… Sent session update with turn detection settings
âœ… Sent Part 1 start request
âœ… Started sending audio to OpenAI via data channel
âœ… Microphone access granted for Realtime API
âœ… Audio capture pipeline set up - ready to send audio chunks
âœ… WebRTC connection fully established
```

### During Conversation:
```
ğŸ¤ User started speaking
ğŸ“ Partial user transcription: "Hello..."
ğŸ“ Partial user transcription: "Hello, I am..."
âœ… Complete user transcription: "Hello, I am a student"
ğŸ“ AI text delta: "That's great! "
ğŸ“ AI text delta: "What are you studying?"
âœ… AI response completed: "That's great! What are you studying?"
â–¶ï¸ AI audio started playing
```

## ğŸ› Common Issues

### Issue: "Browser autoplay policy blocked audio"
**Solution:** Click the "ğŸ”Š Click to Start Audio" button

### Issue: "Data channel not open"
**Solution:** Wait for connection to establish, check WebRTC connection state

### Issue: "No audio chunks being sent"
**Solution:** 
- Check `isCapturingAudio` is `true`
- Check `dataChannel.readyState === 'open'`
- Verify microphone is working (test in other apps)

### Issue: "AI asks multiple questions immediately"
**Solution:**
- Verify `input_audio_buffer.start` was sent
- Check audio chunks are being sent (console should show continuous data)
- Increase `silence_duration_ms` if needed

## âœ… Success Criteria

1. âœ… Microphone captures audio
2. âœ… Audio chunks sent to OpenAI via data channel
3. âœ… AI receives and transcribes user speech
4. âœ… AI responds to specific content (not generic)
5. âœ… AI waits 4 seconds of silence before responding
6. âœ… AI audio plays back correctly
7. âœ… Conversation flows naturally

## ğŸ“ Notes

- **HTTPS Required:** WebRTC needs secure context (HTTPS or localhost)
- **Browser Support:** Chrome/Edge recommended, Firefox should work
- **Microphone:** Must be allowed in browser permissions
- **Network:** Requires stable internet connection for WebRTC
